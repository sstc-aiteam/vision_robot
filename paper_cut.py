import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor
from pyzbar.pyzbar import decode as pyzbar_decode
import warnings
from datetime import datetime
import os

# è¨­ç½®
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore', category=UserWarning)

class SimpleSAM2QRDetector:
    """ç°¡åŒ–çš„ SAM2 QRç¢¼æª¢æ¸¬ç³»çµ± - ç›´æ¥åœ¨åŸåœ–ä¸Šå·¥ä½œ"""
    
    def __init__(self, checkpoint_path, model_cfg_path, standard_qr_size_mm=53.5):
        """åˆå§‹åŒ–"""
        print("ğŸ¤– Loading SAM2 model...")
        self.predictor = SAM2ImagePredictor(build_sam2(model_cfg_path, checkpoint_path))
        self.standard_qr_size_mm = standard_qr_size_mm
        print("âœ… SAM2 model loaded successfully")
    
    def segment_paper(self, image):
        """ä½¿ç”¨SAM2åˆ†å‰²ç´™å¼µ"""
        print("ğŸ“„ Segmenting paper with SAM2...")
        
        # è½‰æ›ç‚ºRGB
        if len(image.shape) == 3:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            image_rgb = image
        
        h, w = image_rgb.shape[:2]
        print(f"ğŸ–¼ï¸ Image size: {w}Ã—{h}")
        
        # ä½¿ç”¨ç°¡å–®çš„ä¸­å¿ƒé»ç­–ç•¥
        with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
            self.predictor.set_image(image_rgb)
            
            # å–®ä¸€ä¸­å¿ƒé»
            input_point = np.array([[w//2, h//2]])
            input_label = np.array([1])
            
            print(f"ğŸ¯ Using center point: ({w//2}, {h//2})")
            
            # é æ¸¬
            masks, scores, logits = self.predictor.predict(
                point_coords=input_point,
                point_labels=input_label,
                multimask_output=True
            )
        
        # é¸æ“‡æœ€ä½³é®ç½©
        best_mask_idx = np.argmax(scores)
        best_mask = masks[best_mask_idx]
        best_score = scores[best_mask_idx]
        
        print(f"âœ… Paper segmentation completed! Score: {best_score:.4f}")
        
        return best_mask, best_score, input_point
    
    def get_paper_corners(self, mask):
        """å¾é®ç½©ç²å–ç´™å¼µè§’é»"""
        print("ğŸ“ Getting paper corners...")
        
        # å¾é®ç½©æå–è¼ªå»“
        mask_uint8 = (mask * 255).astype(np.uint8)
        contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            print("âŒ No contours found")
            return None, None
        
        # æ‰¾æœ€å¤§è¼ªå»“
        contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(contour)
        
        print(f"ğŸ“Š Paper contour area: {area} pixels")
        
        # å¤šé‚Šå½¢è¿‘ä¼¼ç²å–è§’é»
        epsilon = 0.02 * cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, epsilon, True)
        
        if len(approx) >= 4:
            corners = approx.reshape(-1, 2)
            print(f"âœ… Found {len(corners)} corner points")
            return contour, corners
        else:
            # ä½¿ç”¨é‚Šç•ŒçŸ©å½¢ä½œç‚ºå‚™ç”¨
            rect = cv2.minAreaRect(contour)
            box = cv2.boxPoints(rect)
            box = np.int0(box)
            print("âœ… Using bounding rectangle as corners")
            return contour, box
    
    def calculate_paper_dpi(self, corners):
        """æ ¹æ“šç´™å¼µè§’é»è¨ˆç®—DPI"""
        print("ğŸ“ Calculating paper DPI...")
        
        if corners is None or len(corners) < 4:
            print("âŒ Invalid corners for DPI calculation")
            return None
        
        # æ’åºè§’é»ï¼šTL, TR, BR, BL
        center = np.mean(corners, axis=0)
        top_points = sorted(corners, key=lambda p: p[1])[:2]
        bottom_points = sorted(corners, key=lambda p: p[1])[2:]
        top_points = sorted(top_points, key=lambda p: p[0])
        bottom_points = sorted(bottom_points, key=lambda p: p[0])
        ordered = np.array([top_points[0], top_points[1], bottom_points[1], bottom_points[0]])
        
        tl, tr, br, bl = ordered
        
        # è¨ˆç®—ç´™å¼µåƒç´ å°ºå¯¸
        width_px = (np.linalg.norm(tr - tl) + np.linalg.norm(br - bl)) / 2
        height_px = (np.linalg.norm(bl - tl) + np.linalg.norm(br - tr)) / 2
        
        print(f"ğŸ“ Paper dimensions: {width_px:.1f} Ã— {height_px:.1f} px")
        
        # A4æ¨™æº–å°ºå¯¸
        a4_width_mm, a4_height_mm = 210, 297
        
        # åˆ¤æ–·æ–¹å‘ä¸¦è¨ˆç®—DPI
        if width_px > height_px:
            # æ©«å‘
            dpi = width_px / (a4_height_mm / 25.4)
            orientation = "Landscape"
            paper_width_mm = a4_height_mm
            paper_height_mm = a4_width_mm
        else:
            # ç¸±å‘
            dpi = width_px / (a4_width_mm / 25.4)
            orientation = "Portrait"
            paper_width_mm = a4_width_mm
            paper_height_mm = a4_height_mm
        
        px_to_mm = 25.4 / dpi
        
        print(f"ğŸ“‹ Orientation: {orientation}")
        print(f"ğŸ“ DPI: {dpi:.1f}")
        print(f"ğŸ”„ Conversion: {px_to_mm:.4f} mm/px")
        
        return {
            'dpi': dpi,
            'orientation': orientation,
            'px_to_mm': px_to_mm,
            'size_px': {'width': width_px, 'height': height_px},
            'size_mm': {'width': paper_width_mm, 'height': paper_height_mm},
            'corners': ordered
        }
    
    def detect_qr_codes_on_original(self, image):
        """ç›´æ¥åœ¨åŸå§‹åœ–åƒä¸Šæª¢æ¸¬QRç¢¼"""
        print("ğŸ” Detecting QR codes on original image...")
        
        # è½‰æ›ç‚ºç°éš
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        qr_results = []
        found_centers = []
        
        # å˜—è©¦å¤šç¨®é è™•ç†æ–¹æ³•
        methods = [
            ("direct", lambda img: img),
            ("clahe", lambda img: cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8)).apply(img)),
            ("blur", lambda img: cv2.GaussianBlur(img, (3, 3), 0)),
            ("adaptive", lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)),
        ]
        
        for method_name, preprocess in methods:
            print(f"   ğŸ“‹ Trying {method_name} method...")
            processed = preprocess(gray)
            qr_codes = pyzbar_decode(processed)
            
            method_found = 0
            for qr in qr_codes:
                if len(qr.polygon) >= 4:
                    corners = [(point.x, point.y) for point in qr.polygon[:4]]
                    center = (int(np.mean([p[0] for p in corners])), 
                             int(np.mean([p[1] for p in corners])))
                    
                    # æª¢æŸ¥é‡è¤‡
                    is_duplicate = any(abs(center[0] - c[0]) < 50 and abs(center[1] - c[1]) < 50 
                                     for c in found_centers)
                    
                    if not is_duplicate:
                        # è¨ˆç®—QRç¢¼åƒç´ å°ºå¯¸
                        width_px = (np.linalg.norm(np.array(corners[1]) - np.array(corners[0])) + 
                                   np.linalg.norm(np.array(corners[2]) - np.array(corners[3]))) / 2
                        height_px = (np.linalg.norm(np.array(corners[3]) - np.array(corners[0])) + 
                                    np.linalg.norm(np.array(corners[2]) - np.array(corners[1]))) / 2
                        
                        qr_results.append({
                            'id': len(qr_results) + 1,
                            'corners': corners,
                            'center': center,
                            'size_px': {'width': width_px, 'height': height_px},
                            'data': qr.data.decode('utf-8') if qr.data else "",
                            'method': method_name
                        })
                        found_centers.append(center)
                        method_found += 1
            
            print(f"   Found {method_found} new QR codes with {method_name}")
            
            if len(qr_results) >= 4:
                break
        
        print(f"âœ… Total QR codes detected: {len(qr_results)}")
        return qr_results
    
    def calculate_qr_sizes_with_perspective_correction(self, qr_results, paper_info):
        """è¨ˆç®—QRç¢¼å¯¦éš›å°ºå¯¸ - åŠ å…¥é€è¦–æ ¡æ­£"""
        print("ğŸ“Š Calculating QR code sizes with perspective correction...")
        
        if not paper_info:
            print("âŒ No paper info available for size calculation")
            return
        
        corners = paper_info['corners']
        tl, tr, br, bl = corners
        
        # è¨ˆç®—ç´™å¼µçš„é€è¦–è®Šå½¢åƒæ•¸
        paper_width_top = np.linalg.norm(tr - tl)
        paper_width_bottom = np.linalg.norm(br - bl)
        paper_height_left = np.linalg.norm(bl - tl)
        paper_height_right = np.linalg.norm(br - tr)
        
        print(f"ğŸ“ Paper edge lengths:")
        print(f"   Top: {paper_width_top:.1f}px, Bottom: {paper_width_bottom:.1f}px")
        print(f"   Left: {paper_height_left:.1f}px, Right: {paper_height_right:.1f}px")
        
        # A4 æ¨™æº–å°ºå¯¸
        if paper_info['orientation'] == 'Landscape':
            paper_width_mm, paper_height_mm = 297, 210
        else:
            paper_width_mm, paper_height_mm = 210, 297
        
        for qr in qr_results:
            qr_x, qr_y = qr['center']
            
            # è¨ˆç®— QR ç¢¼åœ¨ç´™å¼µä¸­çš„ç›¸å°ä½ç½® (0-1)
            # ä½¿ç”¨é›™ç·šæ€§æ’å€¼æ‰¾åˆ° QR ç¢¼çš„ç´™å¼µåº§æ¨™
            paper_x_ratio, paper_y_ratio = self.get_paper_relative_position(
                qr_x, qr_y, corners
            )
            
            print(f"   QR{qr['id']} position in paper: ({paper_x_ratio:.2f}, {paper_y_ratio:.2f})")
            
            # æ ¹æ“šä½ç½®è¨ˆç®—å±€éƒ¨ DPI
            # åœ¨è©²ä½ç½®æ’å€¼è¨ˆç®—ç´™å¼µçš„å±€éƒ¨åƒç´ å¯†åº¦
            
            # æ°´å¹³æ–¹å‘çš„åƒç´ å¯†åº¦è®ŠåŒ–
            top_dpi = paper_width_top / (paper_width_mm / 25.4)
            bottom_dpi = paper_width_bottom / (paper_width_mm / 25.4)
            local_dpi_horizontal = top_dpi + (bottom_dpi - top_dpi) * paper_y_ratio
            
            # å‚ç›´æ–¹å‘çš„åƒç´ å¯†åº¦è®ŠåŒ–  
            left_dpi = paper_height_left / (paper_height_mm / 25.4)
            right_dpi = paper_height_right / (paper_height_mm / 25.4)
            local_dpi_vertical = left_dpi + (right_dpi - left_dpi) * paper_x_ratio
            
            # ä½¿ç”¨å¹³å‡ DPI
            local_dpi = (local_dpi_horizontal + local_dpi_vertical) / 2
            local_px_to_mm = 25.4 / local_dpi
            
            print(f"   QR{qr['id']} local DPI: {local_dpi:.1f} (vs paper avg: {paper_info['dpi']:.1f})")
            
            # ä½¿ç”¨å±€éƒ¨ DPI è¨ˆç®—å¯¦éš›å°ºå¯¸
            actual_width_mm = qr['size_px']['width'] * local_px_to_mm
            actual_height_mm = qr['size_px']['height'] * local_px_to_mm
            actual_avg_mm = (actual_width_mm + actual_height_mm) / 2
            
            # ç†è«–åƒç´ å°ºå¯¸
            theoretical_px = self.standard_qr_size_mm / local_px_to_mm
            
            # è¨ˆç®—èª¤å·®
            error_mm = actual_avg_mm - self.standard_qr_size_mm
            error_percent = (error_mm / self.standard_qr_size_mm) * 100
            
            qr['analysis'] = {
                'actual_size_mm': {
                    'width': actual_width_mm,
                    'height': actual_height_mm,
                    'avg': actual_avg_mm
                },
                'theoretical_size_mm': self.standard_qr_size_mm,
                'theoretical_size_px': theoretical_px,
                'error_mm': error_mm,
                'error_percent': error_percent,
                'local_dpi': local_dpi,
                'paper_position': (paper_x_ratio, paper_y_ratio)
            }
            
            print(f"   QR{qr['id']}: {actual_avg_mm:.1f}mm ({error_percent:+.1f}%) [corrected]")
    
    def get_paper_relative_position(self, qr_x, qr_y, corners):
        """è¨ˆç®— QR ç¢¼åœ¨ç´™å¼µä¸­çš„ç›¸å°ä½ç½®"""
        tl, tr, br, bl = corners
        
        # ä½¿ç”¨é›™ç·šæ€§æ’å€¼æ‰¾åˆ°ç›¸å°ä½ç½®
        # é¦–å…ˆæ‰¾åˆ° QR åœ¨ç´™å¼µåº§æ¨™ç³»ä¸­çš„ä½ç½®
        
        # è¨ˆç®—ç´™å¼µçš„å‘é‡
        top_vector = tr - tl
        left_vector = bl - tl
        
        # QR é»ç›¸å°æ–¼å·¦ä¸Šè§’çš„å‘é‡
        qr_vector = np.array([qr_x, qr_y]) - tl
        
        # æŠ•å½±åˆ°ä¸Šé‚Šå’Œå·¦é‚Šä¾†ä¼°ç®—ç›¸å°ä½ç½®
        # é€™æ˜¯ä¸€å€‹ç°¡åŒ–çš„æ–¹æ³•ï¼Œå‡è¨­ç´™å¼µæ˜¯è¿‘ä¼¼çŸ©å½¢
        
        # X æ–¹å‘ç›¸å°ä½ç½® (0-1)
        top_length = np.linalg.norm(top_vector)
        if top_length > 0:
            x_ratio = np.dot(qr_vector, top_vector / top_length) / top_length
        else:
            x_ratio = 0.5
        
        # Y æ–¹å‘ç›¸å°ä½ç½® (0-1)
        left_length = np.linalg.norm(left_vector)
        if left_length > 0:
            y_ratio = np.dot(qr_vector, left_vector / left_length) / left_length
        else:
            y_ratio = 0.5
        
        # é™åˆ¶åœ¨ 0-1 ç¯„åœå…§
        x_ratio = max(0, min(1, x_ratio))
        y_ratio = max(0, min(1, y_ratio))
        
        return x_ratio, y_ratio
    
    def display_results(self, original, mask, paper_contour, paper_info, qr_results, prompt_points, save_path=None):
        """é¡¯ç¤ºçµæœ"""
        print("ğŸ“Š Creating visualization...")
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        # 1. åŸåœ–
        axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))
        axes[0].set_title('Original Image', fontweight='bold')
        axes[0].axis('off')
        
        # 2. SAM2åˆ†å‰²
        colored_mask = np.zeros_like(original)
        if mask.dtype != bool:
            mask = mask.astype(bool)
        
        colored_mask[mask, 0] = 0    # Red
        colored_mask[mask, 1] = 255  # Green
        colored_mask[mask, 2] = 0    # Blue
        
        result = cv2.addWeighted(original, 0.4, colored_mask, 0.6, 0)
        
        # ç¹ªè£½æç¤ºé»
        for point in prompt_points:
            cv2.circle(result, tuple(point.astype(int)), 8, (255, 0, 0), -1)
            cv2.circle(result, tuple(point.astype(int)), 10, (255, 255, 255), 2)
        
        axes[1].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
        axes[1].set_title('SAM2 Segmentation\n(Green: Paper, Blue: Prompt)', fontweight='bold')
        axes[1].axis('off')
        
        # 3. A4æª¢æ¸¬
        a4_img = original.copy()
        if paper_contour is not None:
            cv2.drawContours(a4_img, [paper_contour], -1, (255, 0, 0), 3)
            
            # æ¨™è¨˜è§’é»
            if paper_info and 'corners' in paper_info:
                corners = paper_info['corners']
                corner_labels = ['TL', 'TR', 'BR', 'BL']
                for i, corner in enumerate(corners):
                    cv2.circle(a4_img, tuple(corner.astype(int)), 8, (0, 255, 255), -1)
                    cv2.putText(a4_img, corner_labels[i], 
                               tuple(corner.astype(int) + 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        axes[2].imshow(cv2.cvtColor(a4_img, cv2.COLOR_BGR2RGB))
        if paper_info:
            title = f'A4 Paper Detection\n{paper_info["orientation"]} | {paper_info["dpi"]:.0f} DPI'
        else:
            title = 'A4 Paper Detection\n(Failed)'
        axes[2].set_title(title, fontweight='bold')
        axes[2].axis('off')
        
        # 4. QRæª¢æ¸¬çµæœ
        qr_img = original.copy()
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), 
                  (255, 0, 255), (0, 255, 255), (128, 255, 0), (255, 128, 0)]
        
        for i, qr in enumerate(qr_results):
            color = colors[i % len(colors)]
            pts = np.array(qr['corners'], dtype=np.int32)
            cv2.polylines(qr_img, [pts], True, color, 3)
            cv2.circle(qr_img, qr['center'], 15, color, -1)
            cv2.putText(qr_img, f"{qr['id']}", (qr['center'][0] - 8, qr['center'][1] + 6),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        axes[3].imshow(cv2.cvtColor(qr_img, cv2.COLOR_BGR2RGB))
        axes[3].set_title(f'QR Code Detection\nFound: {len(qr_results)} codes', fontweight='bold')
        axes[3].axis('off')
        
        # 5. å°ºå¯¸æ¯”è¼ƒ
        if qr_results and paper_info:
            qr_ids = [f"QR{qr['id']}" for qr in qr_results]
            actual_sizes = [qr['analysis']['actual_size_mm']['avg'] for qr in qr_results]
            theoretical_sizes = [qr['analysis']['theoretical_size_mm'] for qr in qr_results]
            
            x = np.arange(len(qr_ids))
            width = 0.35
            
            axes[4].bar(x - width/2, actual_sizes, width, label='Actual', color='skyblue')
            axes[4].bar(x + width/2, theoretical_sizes, width, label='Theoretical', color='lightcoral')
            axes[4].set_xlabel('QR Codes')
            axes[4].set_ylabel('Size (mm)')
            axes[4].set_title('Size Comparison', fontweight='bold')
            axes[4].set_xticks(x)
            axes[4].set_xticklabels(qr_ids)
            axes[4].legend()
            axes[4].grid(True, alpha=0.3)
            
            # æ¨™è¨»æ•¸å€¼
            for i, (actual, theoretical) in enumerate(zip(actual_sizes, theoretical_sizes)):
                axes[4].text(i - width/2, actual + 1, f'{actual:.1f}', ha='center', va='bottom', fontsize=9)
                axes[4].text(i + width/2, theoretical + 1, f'{theoretical:.1f}', ha='center', va='bottom', fontsize=9)
        else:
            axes[4].text(0.5, 0.5, 'No QR codes or\nno paper info', ha='center', va='center', 
                        transform=axes[4].transAxes, fontsize=16)
            axes[4].set_title('Size Comparison', fontweight='bold')
            axes[4].axis('off')
        
        # 6. èª¤å·®åˆ†æ
        if qr_results and paper_info:
            errors = [abs(qr['analysis']['error_percent']) for qr in qr_results]
            colors_error = ['green' if e < 2 else 'orange' if e < 5 else 'red' for e in errors]
            
            bars = axes[5].bar(qr_ids, errors, color=colors_error)
            axes[5].set_xlabel('QR Codes')
            axes[5].set_ylabel('Error (%)')
            axes[5].set_title('Measurement Error', fontweight='bold')
            axes[5].axhline(y=2, color='green', linestyle='--', alpha=0.7, label='<2%')
            axes[5].axhline(y=5, color='orange', linestyle='--', alpha=0.7, label='<5%')
            axes[5].legend()
            axes[5].grid(True, alpha=0.3)
            
            # æ¨™è¨»æ•¸å€¼
            for bar, error in zip(bars, errors):
                height = bar.get_height()
                axes[5].text(bar.get_x() + bar.get_width()/2., height + 0.1,
                            f'{error:.1f}%', ha='center', va='bottom', fontsize=9, fontweight='bold')
        else:
            axes[5].text(0.5, 0.5, 'No error analysis\navailable', ha='center', va='center', 
                        transform=axes[5].transAxes, fontsize=16)
            axes[5].set_title('Error Analysis', fontweight='bold')
            axes[5].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… Results saved to: {save_path}")
        
        plt.show()
    
    def process_image(self, image_path, save_results=True):
        """è™•ç†åœ–åƒçš„ä¸»è¦å‡½æ•¸"""
        print("="*60)
        print("ğŸš€ Simple SAM2 QR Detection System")
        print("="*60)
        
        # è®€å–åœ–åƒ
        image = cv2.imread(image_path)
        if image is None:
            print("âŒ Cannot read image")
            return None
        
        print(f"ğŸ“– Image: {image.shape[1]}Ã—{image.shape[0]} px")
        
        # æ­¥é©Ÿ1: SAM2åˆ†å‰²ç´™å¼µ
        mask, score, prompt_points = self.segment_paper(image)
        if score < 0.5:
            print("âŒ Low segmentation confidence")
            return None
        
        # æ­¥é©Ÿ2: ç²å–ç´™å¼µè§’é»ä¸¦è¨ˆç®—DPI
        paper_contour, paper_corners = self.get_paper_corners(mask)
        paper_info = self.calculate_paper_dpi(paper_corners)
        
        # æ­¥é©Ÿ3: ç›´æ¥åœ¨åŸåœ–ä¸Šæª¢æ¸¬QRç¢¼
        qr_results = self.detect_qr_codes_on_original(image)
        
        # æ­¥é©Ÿ4: è¨ˆç®—QRç¢¼å°ºå¯¸ï¼ˆå¦‚æœæœ‰ç´™å¼µè³‡è¨Šï¼‰
        if paper_info:
            self.calculate_qr_sizes_with_perspective_correction(qr_results, paper_info)
        
        # æ­¥é©Ÿ5: é¡¯ç¤ºçµæœ
        save_path = None
        if save_results:
            base_name = os.path.splitext(os.path.basename(image_path))[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = f"{base_name}_simple_sam2_qr_results_{timestamp}.png"
        
        self.display_results(image, mask, paper_contour, paper_info, qr_results, prompt_points, save_path)
        
        
        return {
            'paper_info': paper_info,
            'qr_results': qr_results,
            'save_path': save_path
        }

# ä¸»ç¨‹åº
if __name__ == "__main__":
    # é…ç½®
    checkpoint_path = "/home/itrib30156/llm_vision/sam/sam2/checkpoints/sam2.1_hiera_large.pt"
    model_cfg_path = "/home/itrib30156/llm_vision/sam/sam2.1_hiera_l.yaml"
    image_path = "/home/itrib30156/llm_vision/712224.jpg"
    standard_qr_size_mm = 53.5  # QRç¢¼æ¨™æº–å°ºå¯¸ï¼ˆmmï¼‰
    
    # æª¢æŸ¥ç’°å¢ƒ
    print("ğŸ¯ Starting Simple SAM2 QR Detection System...")
    if torch.cuda.is_available():
        print("âœ… CUDA available")
    else:
        print("âš ï¸ Using CPU (slower)")
    
    try:
        # åˆå§‹åŒ–æª¢æ¸¬å™¨
        detector = SimpleSAM2QRDetector(checkpoint_path, model_cfg_path, standard_qr_size_mm)
        
        # è™•ç†åœ–åƒ
        results = detector.process_image(image_path, save_results=True)
        
        if results:
            print("\nğŸ‰ Processing completed successfully!")
            print(f"ğŸ“Š Results: {len(results['qr_results'])} QR codes detected")
            if results['save_path']:
                print(f"ğŸ’¾ Saved to: {results['save_path']}")
        else:
            print("\nâŒ Processing failed")
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()